{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCLAIMER: Please read the file before you run it because the tokenizer takes about 6 hours to run\n",
    "\n",
    "# Also FYI, the Search Query Input is at the end of the Notebook (before Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "#### You can find the tokenized data at: CSVData/Tokenized_Allformatdata.csv\n",
    "#### Vocabulary at: CSVData/Vocab_token.csv\n",
    "#### TF-IDF of the blog at: Pickle/blog_vector_tfidf.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets dive into the code itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as et\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "import spacy\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading our processed data from all csv files\n",
    "df = pd.read_csv('CSVData/Allformatdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678194, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Astrosign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000331</td>\n",
       "      <td>31,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Well, everyone got up and going...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000331</td>\n",
       "      <td>29,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      My four-year old never stops ta...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Actually it's not raining yet, ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Ha! Just set up my RSS feed - t...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Oh, which just reminded me, we ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id         Date                                               Post  \\\n",
       "0  1000331  31,May,2004  \\n\\n\\t \\n      Well, everyone got up and going...   \n",
       "1  1000331  29,May,2004  \\n\\n\\t \\n      My four-year old never stops ta...   \n",
       "2  1000331  28,May,2004  \\n\\n\\t \\n      Actually it's not raining yet, ...   \n",
       "3  1000331  28,May,2004  \\n\\n\\t \\n      Ha! Just set up my RSS feed - t...   \n",
       "4  1000331  28,May,2004  \\n\\n\\t \\n      Oh, which just reminded me, we ...   \n",
       "\n",
       "   Gender  Age Industry Astrosign  \n",
       "0  female   37   indUnk       Leo  \n",
       "1  female   37   indUnk       Leo  \n",
       "2  female   37   indUnk       Leo  \n",
       "3  female   37   indUnk       Leo  \n",
       "4  female   37   indUnk       Leo  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if all the files have been included in our df\n",
    "df['Id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645275    \\n\\n\\t \\n      Just to start, a little about m...\n",
      "645276    \\n\\n\\t \\n      Today especially my butt seems ...\n",
      "645277    \\n\\n\\t \\n      Last night Disney held its annu...\n",
      "645278    \\n\\n\\t \\n      It has been a while since I las...\n",
      "645279    \\n\\n\\t \\n      Yesterday Hannah posted a quote...\n",
      "                                ...                        \n",
      "645348    \\n\\n\\t \\n      As most of you know, my biggest...\n",
      "645349    \\n\\n\\t \\n      Now for the weekend update:   O...\n",
      "645350    \\n\\n\\t \\n      Friday night was uneventful--wh...\n",
      "645351    \\n\\n\\t \\n      It's been a good Sunday; Enligh...\n",
      "645352    \\n\\n\\t \\n      What a week�.what a weekend! Ba...\n",
      "Name: Post, Length: 78, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Trying to fetch a file and randomly checking out parameters\n",
    "print(df[df['Id']==813360]['Post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t \n",
      "      Today especially my butt seems to have formed a perfect mold of my chair. I worked through lunch due to a high level mouse requesting ridiculous data. Why the bottom must suffer for the top I'll  never get, shouldn't it be the other way around. I mean, if I made 6 figures I would have no problem parking my 745 BMW myself--actually I'd prefer to park it myself. But here at Disney, the big shots not only get a car allowance every month to help pay for their beauties but they get their cars valet'd everyday. Yes that's right. The rest of us, not in the preferred mouse club, must circle around the parking structure finding the widest compact parking space so our \"un-luxury\" cars don't get more dings.  Really, the more you get paid the fewer the benefits you should receive. It is those of us that don't get paid 6 figures who should get the benefits to make up for the limited funds. (Those of you who don't make bank and are far from it will completely agree I'm sure. And when I make 6 figures--yes I said when--I'm won't agree with me.)  So life is good right now. The poor soul who has bought my old car rescued me from financial debt this month, I have two job opportunities on the horizon, Hannah is coming home in 13 days, the girls and I are going to party our asses off in Vegas in two weeks, and I have 2 dates this weekend. I'm not sure what it is in LA but I've never dated so much in my life. You'd think that you'd date the most in college, well this has proven not to be true for most. I think I went on like 3 formal dates in college total. The \"lets hang out at my house\" offers came up way  more often than the \"lets go out, eat dinner, talk and get to know each other...\"  It can't help that many of the boys, yes boys, I met were at the club. What do I expect if our first interaction is my ass and their crotch? Funny though, we always tried NOT to meet men at the club but for some reason most of the guys there are trying to meet a girl. (I'm sure many of you are like, duhhhh) Note: there's a reason the music is loud a the club...I'm not trying to talk to you I'm trying to dance with you or avoid you.   I'm moving in January, please start praying now because I'll need all the help I can get. I have more stuff than I even know of and moving 5 times in the last 5 years hasn't taught me anything about getting rid of things or not buying more things. Issues...Kim I need you help!!!  Ta Ta for now...my random thoughts have subsided. Oh, FYI--I've discovered why my ass is getting fatter working here. Today I didn't spend a dime and just munched on Disney food. This is what I ate: a bagel (wheat...only healthy thing all day) half with Peanut Butter and half with Cream Cheese, 5 small raspberry jam cookies, a Balance Bar, 1/3 of a cinnamon roll, and half a roast beef sandwich and I've been sitting here all day except for the walk to the kitchen, 2 trips to the bathroom, and 1 to the sink. YA MAN....I'm one sexy bitch!  (I did drink green tea which is mucho good for me) \n",
      "     \n",
      "\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Id']==813360]['Post'][645276])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer (tokenize, lemmatize and remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "#create list of punctuations and stopwords\n",
    "punctuations = string.punctuation\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#function for data cleaning and processing\n",
    "#This can be further enhanced by adding / removing reg-exps as desired.\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    " \n",
    "    #remove distracting single quotes\n",
    "    sentence = re.sub('\\'','',sentence)\n",
    "\n",
    "    #remove digits and words containing digits\n",
    "    sentence = re.sub('\\w*\\d\\w*','',sentence)\n",
    "\n",
    "    #replace extra spaces with single space\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    #remove unwanted lines starting from special charcters\n",
    "    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n",
    "    sentence = re.sub(r'\\n!.*','',sentence)\n",
    "    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n",
    "    \n",
    "    #remove non-breaking new line characters\n",
    "    sentence = re.sub(r'\\n',' ',sentence)\n",
    "    \n",
    "    #remove punctunations\n",
    "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n",
    "    \n",
    "    #creating token object\n",
    "    tokens = spacy_nlp(sentence)\n",
    "    \n",
    "    #lower, strip and lemmatize\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    \n",
    "    #remove stopwords, and exclude words less than 2 characters\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word) > 2]\n",
    "    \n",
    "    #return tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Astrosign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000331</td>\n",
       "      <td>31,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Well, everyone got up and going...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000331</td>\n",
       "      <td>29,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      My four-year old never stops ta...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Actually it's not raining yet, ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Ha! Just set up my RSS feed - t...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000331</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Oh, which just reminded me, we ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678189</th>\n",
       "      <td>963380</td>\n",
       "      <td>04,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      I was pretty close to right on ...</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678190</th>\n",
       "      <td>963380</td>\n",
       "      <td>04,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      On the way home tonight I happe...</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678191</th>\n",
       "      <td>963380</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Some things I didn't touch on. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678192</th>\n",
       "      <td>963380</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      It's been an interesting week. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678193</th>\n",
       "      <td>963380</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Alright, here's the breakdown a...</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id            Date  \\\n",
       "0       1000331     31,May,2004   \n",
       "1       1000331     29,May,2004   \n",
       "2       1000331     28,May,2004   \n",
       "3       1000331     28,May,2004   \n",
       "4       1000331     28,May,2004   \n",
       "...         ...             ...   \n",
       "678189   963380    04,July,2004   \n",
       "678190   963380    04,July,2004   \n",
       "678191   963380    03,July,2004   \n",
       "678192   963380    03,July,2004   \n",
       "678193   963380  03,August,2004   \n",
       "\n",
       "                                                     Post  Gender  Age  \\\n",
       "0       \\n\\n\\t \\n      Well, everyone got up and going...  female   37   \n",
       "1       \\n\\n\\t \\n      My four-year old never stops ta...  female   37   \n",
       "2       \\n\\n\\t \\n      Actually it's not raining yet, ...  female   37   \n",
       "3       \\n\\n\\t \\n      Ha! Just set up my RSS feed - t...  female   37   \n",
       "4       \\n\\n\\t \\n      Oh, which just reminded me, we ...  female   37   \n",
       "...                                                   ...     ...  ...   \n",
       "678189  \\n\\n\\t \\n      I was pretty close to right on ...    male   24   \n",
       "678190  \\n\\n\\t \\n      On the way home tonight I happe...    male   24   \n",
       "678191  \\n\\n\\t \\n      Some things I didn't touch on. ...    male   24   \n",
       "678192  \\n\\n\\t \\n      It's been an interesting week. ...    male   24   \n",
       "678193  \\n\\n\\t \\n      Alright, here's the breakdown a...    male   24   \n",
       "\n",
       "       Industry Astrosign  \n",
       "0        indUnk       Leo  \n",
       "1        indUnk       Leo  \n",
       "2        indUnk       Leo  \n",
       "3        indUnk       Leo  \n",
       "4        indUnk       Leo  \n",
       "...         ...       ...  \n",
       "678189  Student    Cancer  \n",
       "678190  Student    Cancer  \n",
       "678191  Student    Cancer  \n",
       "678192  Student    Cancer  \n",
       "678193  Student    Cancer  \n",
       "\n",
       "[678194 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakbuddha/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#Using tqdm to see the progress of running a file\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 678194/678194 [6:05:44<00:00, 30.90it/s]    \n"
     ]
    }
   ],
   "source": [
    "#Tokenize our ENTIRE Dataset\n",
    "df['Post_tokenized'] = df['Post'].progress_map(lambda x: spacy_tokenizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uff, that took 6 hours!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import operator\n",
    "\n",
    "## Create Vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "for doc in df.Post_tokenized:\n",
    "        vocabulary.update(doc)\n",
    "        \n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "# Intializating the tfIdf model\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer,vocabulary=vocabulary,lowercase=False)\n",
    "\n",
    "# Fit the TfIdf model\n",
    "blog_vector = tfidf.fit_transform(df.Post_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<678194x644452 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40958261 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644452"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678194, 644452)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Getting similar words for our query from Spacy Large Vocab library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createKeywordsVectors(keyword, nlp):\n",
    "    doc = nlp(keyword)  # convert to document object\n",
    "\n",
    "    return doc.vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to find cosine similarity using Spacy and Spatial distance\n",
    "def cosineSimilarity(vect1, vect2):\n",
    "    # return cosine distance\n",
    "    return 1 - spatial.distance.cosine(vect1, vect2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to find similar words\n",
    "def getSimilarWords(keyword, nlp):\n",
    "    similarity_list = []\n",
    "\n",
    "    keyword_vector = createKeywordsVectors(keyword, nlp)\n",
    "\n",
    "    for tokens in nlp.vocab:\n",
    "        if (tokens.has_vector):\n",
    "            if (tokens.is_lower):\n",
    "                if (tokens.is_alpha):\n",
    "                    similarity_list.append((tokens, cosineSimilarity(keyword_vector, tokens.vector)))\n",
    "\n",
    "    similarity_list = sorted(similarity_list, key=lambda item: -item[1])\n",
    "    similarity_list = similarity_list[:30]\n",
    "\n",
    "    top_similar_words = [item[0].text for item in similarity_list]\n",
    "\n",
    "    top_similar_words = top_similar_words[:10]\n",
    "    top_similar_words.append(keyword)\n",
    "\n",
    "    for token in nlp(keyword):\n",
    "        top_similar_words.insert(0, token.lemma_)\n",
    "\n",
    "    for words in top_similar_words:\n",
    "        if words.endswith(\"s\"):\n",
    "            top_similar_words.append(words[0:len(words)-1])\n",
    "\n",
    "    top_similar_words = list(set(top_similar_words))\n",
    "\n",
    "    top_similar_words = [words for words in top_similar_words]\n",
    "    \n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    \n",
    "    #remove stopwords, and exclude words less than 2 characters\n",
    "    top_similar_words = [word for word in top_similar_words if word not in stop_words and word not in punctuations and len(word) > 2]\n",
    "\n",
    "\n",
    "    return \", \".join(top_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking in our tokenized query entry and finding similar matches\n",
    "def Similarkey(query_token):\n",
    "    \n",
    "    #Finding all similar words\n",
    "    similarkey = []\n",
    "    for i in query_token:\n",
    "        #Getting similar words\n",
    "        result = getSimilarWords(i,nlp)\n",
    "        result = result.split(', ')\n",
    "        for el in result:\n",
    "            similarkey.append(el)\n",
    "            \n",
    "    #Joining our results with our query_token        \n",
    "    joinedkey = similarkey + query_token\n",
    "    \n",
    "    #Removing duplicates in our joinedkey\n",
    "    j_key = set(joinedkey)\n",
    "    j_key = list(joinedkey)\n",
    "    \n",
    "    #Returning similar words along withour query tokens as a list\n",
    "    return(j_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our SemanticSearch combining similarity of words and feeding it into a TF-IDF vectorizer\n",
    "\n",
    "## Basically Section 2 -- > Section 1 = Our Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SemanticSearch(word_input,x):\n",
    "    #Creating a dataframe to store the token of the word_input as list\n",
    "    query_df = pd.DataFrame(columns=['token'])    \n",
    "\n",
    "    query_token = spacy_tokenizer(word_input)\n",
    "    similar_token = Similarkey(query_token)\n",
    "    query_df.loc[0,'token'] = query_token\n",
    "\n",
    "    #Transforming our input query as a TF IDF vector\n",
    "    input_vector = tfidf.transform(query_df['token'])   \n",
    "\n",
    "    #Getting cosine similarities\n",
    "    cosines = cosine_similarity(input_vector, blog_vector).flatten()\n",
    "\n",
    "    #Ordering our results in descending order\n",
    "    out = np.array(cosines).argsort()[-x:][::-1]\n",
    "\n",
    "    #Seeing the results of our query in our original dataframe\n",
    "    result_df = df.loc[out]\n",
    "    result_df['Relevance'] = cosines[out]\n",
    "    return(result_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Tokenized Data, Vocabulary and also storing our blog_vector (from TDFIDF) along with Vocabulary (again) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('CSVData/Tokenized_Allformatdata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df.to_csv('CSVData/Vocab_token.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(blog_vector, open(\"Pickle/blog_vector_tfidf.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vocabulary,open(\"Pickle/vocabulary.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINALLY HERE IS OUR SEARCH ENGINE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Semantic Search Engine!\n",
      "\n",
      "Kindly enter the keyword/sentence/query you are looking for:\t\n",
      "Sunshine and blossoms\n",
      "\n",
      " How many relevant results who you like me to show?:\t\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Astrosign</th>\n",
       "      <th>Post_tokenized</th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346474</th>\n",
       "      <td>317581</td>\n",
       "      <td>27,May,2004</td>\n",
       "      <td>\\n\\n\\t \\n      You are my sunshine, my only su...</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>[sunshine, sunshine, happy, sky, grey, know, d...</td>\n",
       "      <td>0.561988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324115</th>\n",
       "      <td>2967696</td>\n",
       "      <td>04,June,2004</td>\n",
       "      <td>\\n\\n\\n       \\n       urlLink    birthday blos...</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Aries</td>\n",
       "      <td>[urllink, birthday, blossom, nbsp, urllink]</td>\n",
       "      <td>0.555443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489275</th>\n",
       "      <td>605396</td>\n",
       "      <td>15,March,2003</td>\n",
       "      <td>\\n\\n    \\n       Ah, the sunshine has returned...</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>[sunshine, return]</td>\n",
       "      <td>0.538309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675887</th>\n",
       "      <td>4156027</td>\n",
       "      <td>11,August,2004</td>\n",
       "      <td>\\n\\n\\t \\n       urlLink    on my way home, sun...</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>[urllink, way, home, sunshine]</td>\n",
       "      <td>0.533313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126369</th>\n",
       "      <td>3877921</td>\n",
       "      <td>13,August,2004</td>\n",
       "      <td>\\n\\n\\n       \\n      By  Sixpence None the Ric...</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[sixpence, rich, time, question, world, leave,...</td>\n",
       "      <td>0.533122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146411</th>\n",
       "      <td>4056181</td>\n",
       "      <td>02,August,2004</td>\n",
       "      <td>\\n\\n     \\n       urlLink Good Morning Sunshin...</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>[urllink, good, morning, sunshine]</td>\n",
       "      <td>0.529344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33847</th>\n",
       "      <td>2800347</td>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>\\n\\n    \\n       \\n       urlLink    Blossom a...</td>\n",
       "      <td>female</td>\n",
       "      <td>41</td>\n",
       "      <td>HumanResources</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[urllink, blossom, piss, company, nbsp, urllink]</td>\n",
       "      <td>0.501577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432359</th>\n",
       "      <td>3691135</td>\n",
       "      <td>08,August,2004</td>\n",
       "      <td>\\n\\n\\t \\n      But hey look, there's sunshine ...</td>\n",
       "      <td>female</td>\n",
       "      <td>41</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[hey, look, sunshine, today, urllink]</td>\n",
       "      <td>0.486142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652925</th>\n",
       "      <td>887044</td>\n",
       "      <td>13,september,2003</td>\n",
       "      <td>\\n\\n\\n       \\n      Somehow my little sunshin...</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>[little, sunshine, person, change, overnight, ...</td>\n",
       "      <td>0.484833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137512</th>\n",
       "      <td>3971038</td>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Made a wish, I can dream I can ...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[wish, dream, want, afraid, live, life, fulfil...</td>\n",
       "      <td>0.470240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id               Date  \\\n",
       "346474   317581        27,May,2004   \n",
       "324115  2967696       04,June,2004   \n",
       "489275   605396      15,March,2003   \n",
       "675887  4156027     11,August,2004   \n",
       "126369  3877921     13,August,2004   \n",
       "146411  4056181     02,August,2004   \n",
       "33847   2800347       14,July,2004   \n",
       "432359  3691135     08,August,2004   \n",
       "652925   887044  13,september,2003   \n",
       "137512  3971038       11,July,2004   \n",
       "\n",
       "                                                     Post  Gender  Age  \\\n",
       "346474  \\n\\n\\t \\n      You are my sunshine, my only su...    male   26   \n",
       "324115  \\n\\n\\n       \\n       urlLink    birthday blos...  female   27   \n",
       "489275  \\n\\n    \\n       Ah, the sunshine has returned...    male   35   \n",
       "675887  \\n\\n\\t \\n       urlLink    on my way home, sun...    male   26   \n",
       "126369  \\n\\n\\n       \\n      By  Sixpence None the Ric...  female   16   \n",
       "146411  \\n\\n     \\n       urlLink Good Morning Sunshin...  female   25   \n",
       "33847   \\n\\n    \\n       \\n       urlLink    Blossom a...  female   41   \n",
       "432359  \\n\\n\\t \\n      But hey look, there's sunshine ...  female   41   \n",
       "652925  \\n\\n\\n       \\n      Somehow my little sunshin...  female   23   \n",
       "137512  \\n\\n\\t \\n      Made a wish, I can dream I can ...    male   23   \n",
       "\n",
       "                    Industry    Astrosign  \\\n",
       "346474            Technology      Scorpio   \n",
       "324115  Communications-Media        Aries   \n",
       "489275                indUnk      Scorpio   \n",
       "675887               Student  Sagittarius   \n",
       "126369               Student        Libra   \n",
       "146411            Non-Profit        Virgo   \n",
       "33847         HumanResources       Gemini   \n",
       "432359                  Arts       Gemini   \n",
       "652925                indUnk       Pisces   \n",
       "137512               Student       Gemini   \n",
       "\n",
       "                                           Post_tokenized  Relevance  \n",
       "346474  [sunshine, sunshine, happy, sky, grey, know, d...   0.561988  \n",
       "324115        [urllink, birthday, blossom, nbsp, urllink]   0.555443  \n",
       "489275                                 [sunshine, return]   0.538309  \n",
       "675887                     [urllink, way, home, sunshine]   0.533313  \n",
       "126369  [sixpence, rich, time, question, world, leave,...   0.533122  \n",
       "146411                 [urllink, good, morning, sunshine]   0.529344  \n",
       "33847    [urllink, blossom, piss, company, nbsp, urllink]   0.501577  \n",
       "432359              [hey, look, sunshine, today, urllink]   0.486142  \n",
       "652925  [little, sunshine, person, change, overnight, ...   0.484833  \n",
       "137512  [wish, dream, want, afraid, live, life, fulfil...   0.470240  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Welcome to the Semantic Search Engine!\\n\\nKindly enter the keyword/sentence/query you are looking for:\\t\")\n",
    "word = input()\n",
    "print(\"\\n How many relevant results who you like me to show?:\\t\")\n",
    "r = input()\n",
    "r = int(r)\n",
    "\n",
    "result_df = SemanticSearch(word,r)\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Semantic Search Engine!\n",
      "\n",
      "Kindly enter the keyword/sentence/query you are looking for:\t\n",
      "Rains \n",
      "\n",
      " How many relevant results who you like me to show?:\t\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Astrosign</th>\n",
       "      <th>Post_tokenized</th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494113</th>\n",
       "      <td>727002</td>\n",
       "      <td>22,February,2003</td>\n",
       "      <td>\\n\\n\\n       \\n      rain, rain, rain, rain, r...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Leo</td>\n",
       "      <td>[rain, rain, rain, rain, rain, rain, rain, rai...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538870</th>\n",
       "      <td>1155029</td>\n",
       "      <td>29,May,2004</td>\n",
       "      <td>\\n\\n     \\n      No rain.\\n     \\n    \\n</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>[rain]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570124</th>\n",
       "      <td>1596894</td>\n",
       "      <td>08,April,2004</td>\n",
       "      <td>\\n\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t   aloneaalloonn...</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[aloneaalloonneeaaalllooonnneeeaaaalllloooonnn...</td>\n",
       "      <td>0.997887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605477</th>\n",
       "      <td>477665</td>\n",
       "      <td>03,November,2003</td>\n",
       "      <td>\\n\\n\\n       \\n      rain. it rained. I fell. ...</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>[rain, rain, fall, rain, love, rain, lose, rai...</td>\n",
       "      <td>0.977105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438484</th>\n",
       "      <td>3734683</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>\\n\\n     \\n       urlLink    The rain\\n     \\n...</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[urllink, rain]</td>\n",
       "      <td>0.904114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123662</th>\n",
       "      <td>3859699</td>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n       urlLink    rain&amp;nbsp; urlLink ...</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>[urllink, rain, nbsp, urllink, rain, rain, eye]</td>\n",
       "      <td>0.901894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89776</th>\n",
       "      <td>3575606</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>\\n\\n    \\n       \\n      Driving in the rain.R...</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>[drive, rain, rain, head, rain, sock, wet, rai...</td>\n",
       "      <td>0.892373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289847</th>\n",
       "      <td>2597250</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>\\n\\n\\t \\n      wow...i love rain so much.  I w...</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[wow, love, rain, nice, long, run, rain, man, ...</td>\n",
       "      <td>0.850163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344319</th>\n",
       "      <td>316316</td>\n",
       "      <td>10,February,2004</td>\n",
       "      <td>\\n\\n\\n       \\n      By no means a complete li...</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Education</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>[mean, complete, listing, think, rain, time, s...</td>\n",
       "      <td>0.843418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409178</th>\n",
       "      <td>3554150</td>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>\\n\\n    \\n       \\n      Today, my day off. I ...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[today, day, wake, stay, cuz, pour, rain, rain...</td>\n",
       "      <td>0.831060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id              Date  \\\n",
       "494113   727002  22,February,2003   \n",
       "538870  1155029       29,May,2004   \n",
       "570124  1596894     08,April,2004   \n",
       "605477   477665  03,November,2003   \n",
       "438484  3734683      01,July,2004   \n",
       "123662  3859699      14,July,2004   \n",
       "89776   3575606      09,June,2004   \n",
       "289847  2597250    05,August,2004   \n",
       "344319   316316  10,February,2004   \n",
       "409178  3554150      09,July,2004   \n",
       "\n",
       "                                                     Post  Gender  Age  \\\n",
       "494113  \\n\\n\\n       \\n      rain, rain, rain, rain, r...    male   23   \n",
       "538870           \\n\\n     \\n      No rain.\\n     \\n    \\n  female   17   \n",
       "570124  \\n\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t   aloneaalloonn...    male   26   \n",
       "605477  \\n\\n\\n       \\n      rain. it rained. I fell. ...  female   25   \n",
       "438484  \\n\\n     \\n       urlLink    The rain\\n     \\n...  female   27   \n",
       "123662  \\n\\n\\t \\n       urlLink    rain&nbsp; urlLink ...  female   23   \n",
       "89776   \\n\\n    \\n       \\n      Driving in the rain.R...  female   24   \n",
       "289847  \\n\\n\\t \\n      wow...i love rain so much.  I w...  female   16   \n",
       "344319  \\n\\n\\n       \\n      By no means a complete li...  female   24   \n",
       "409178  \\n\\n    \\n       \\n      Today, my day off. I ...    male   23   \n",
       "\n",
       "         Industry Astrosign  \\\n",
       "494113   Internet       Leo   \n",
       "538870    Student       Leo   \n",
       "570124       Arts     Libra   \n",
       "605477     indUnk       Leo   \n",
       "438484     indUnk    Gemini   \n",
       "123662   Internet    Cancer   \n",
       "89776      indUnk    Taurus   \n",
       "289847     indUnk    Gemini   \n",
       "344319  Education     Virgo   \n",
       "409178     indUnk     Libra   \n",
       "\n",
       "                                           Post_tokenized  Relevance  \n",
       "494113  [rain, rain, rain, rain, rain, rain, rain, rai...   1.000000  \n",
       "538870                                             [rain]   1.000000  \n",
       "570124  [aloneaalloonneeaaalllooonnneeeaaaalllloooonnn...   0.997887  \n",
       "605477  [rain, rain, fall, rain, love, rain, lose, rai...   0.977105  \n",
       "438484                                    [urllink, rain]   0.904114  \n",
       "123662    [urllink, rain, nbsp, urllink, rain, rain, eye]   0.901894  \n",
       "89776   [drive, rain, rain, head, rain, sock, wet, rai...   0.892373  \n",
       "289847  [wow, love, rain, nice, long, run, rain, man, ...   0.850163  \n",
       "344319  [mean, complete, listing, think, rain, time, s...   0.843418  \n",
       "409178  [today, day, wake, stay, cuz, pour, rain, rain...   0.831060  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Welcome to the Semantic Search Engine!\\n\\nKindly enter the keyword/sentence/query you are looking for:\\t\")\n",
    "word = input()\n",
    "print(\"\\n How many relevant results who you like me to show?:\\t\")\n",
    "r = input()\n",
    "r = int(r)\n",
    "\n",
    "result_df = SemanticSearch(word,r)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more final run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Semantic Search Engine!\n",
      "\n",
      "Kindly enter the keyword/sentence/query you are looking for:\t\n",
      "The weather is really nice dont you think?\n",
      "\n",
      " How many relevant results who you like me to show?:\t\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Astrosign</th>\n",
       "      <th>Post_tokenized</th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57148</th>\n",
       "      <td>3348936</td>\n",
       "      <td>17,May,2004</td>\n",
       "      <td>\\n\\n    \\n       As always the weather has let...</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[weather, let]</td>\n",
       "      <td>0.667551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602779</th>\n",
       "      <td>449628</td>\n",
       "      <td>27,February,2003</td>\n",
       "      <td>\\n\\n\\n       \\n        urlLink Weather from We...</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>[urllink, weather, weatherbug, include, weathe...</td>\n",
       "      <td>0.588184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592824</th>\n",
       "      <td>320317</td>\n",
       "      <td>06,January,2002</td>\n",
       "      <td>\\n\\n    \\n         Little under the weather to...</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>[little, weather, today, feel]</td>\n",
       "      <td>0.574015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29972</th>\n",
       "      <td>2627097</td>\n",
       "      <td>06,February,2004</td>\n",
       "      <td>\\n\\n    \\n       \\n      Ah HA! I have real we...</td>\n",
       "      <td>female</td>\n",
       "      <td>47</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>[real, weather, need]</td>\n",
       "      <td>0.573347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31157</th>\n",
       "      <td>2661577</td>\n",
       "      <td>18,July,2004</td>\n",
       "      <td>\\n\\n    \\n       11:00am 1-19-2004  urlLink My...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[urllink, weather, suck]</td>\n",
       "      <td>0.573257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462227</th>\n",
       "      <td>3932756</td>\n",
       "      <td>04,August,2004</td>\n",
       "      <td>\\n\\n     \\n         Great weather we are havin...</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>[great, weather, far]</td>\n",
       "      <td>0.570216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635702</th>\n",
       "      <td>75671</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>\\n\\n     \\n       urlLink    If i am talking a...</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Aries</td>\n",
       "      <td>[urllink, talk, weather, mean]</td>\n",
       "      <td>0.566359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154433</th>\n",
       "      <td>4147395</td>\n",
       "      <td>11,August,2004</td>\n",
       "      <td>\\n\\n\\t \\n      I fucking hate The Weather Chan...</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Military</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>[fucking, hate, weather, channel, seriously, c...</td>\n",
       "      <td>0.561749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288270</th>\n",
       "      <td>2576645</td>\n",
       "      <td>15,March,2004</td>\n",
       "      <td>\\n\\n\\t \\n      As you may have noticed, I have...</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>[notice, change, template, blog, parade, templ...</td>\n",
       "      <td>0.557421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504350</th>\n",
       "      <td>1107146</td>\n",
       "      <td>17,February,2003</td>\n",
       "      <td>\\n\\n    \\n       \\n      Nice.\\n      \\n</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514795</th>\n",
       "      <td>958176</td>\n",
       "      <td>13,March,2003</td>\n",
       "      <td>\\n\\n    \\n       \\n      Will, be nice.\\n      \\n</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228003</th>\n",
       "      <td>1842721</td>\n",
       "      <td>05,February,2004</td>\n",
       "      <td>\\n\\n\\t \\n      Nice. \\n    \\n</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92294</th>\n",
       "      <td>3593363</td>\n",
       "      <td>29,July,2004</td>\n",
       "      <td>\\n\\n\\t \\n      I've got nothing nice to say. \\...</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514751</th>\n",
       "      <td>958176</td>\n",
       "      <td>17,February,2003</td>\n",
       "      <td>\\n\\n    \\n       \\n      Nice.\\n      \\n</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590083</th>\n",
       "      <td>307112</td>\n",
       "      <td>02,July,2004</td>\n",
       "      <td>\\n\\n     \\n      nice \\n     \\n    \\n</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572927</th>\n",
       "      <td>1784456</td>\n",
       "      <td>24,March,2002</td>\n",
       "      <td>\\n\\n    \\n       \\n      You're so nice to me....</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504394</th>\n",
       "      <td>1107146</td>\n",
       "      <td>13,March,2003</td>\n",
       "      <td>\\n\\n    \\n       \\n      Will, be nice.\\n      \\n</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>0.529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30618</th>\n",
       "      <td>2637211</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td>\\n\\n    \\n       \\n      Ever wonder what the ...</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>[wonder, weather, like, house, jerm, weather, ...</td>\n",
       "      <td>0.520364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104290</th>\n",
       "      <td>3688047</td>\n",
       "      <td>24,June,2004</td>\n",
       "      <td>\\n\\n\\t \\n      English weather sucks!\\n     \\n...</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>[english, weather, suck]</td>\n",
       "      <td>0.490733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234168</th>\n",
       "      <td>1915813</td>\n",
       "      <td>25,April,2004</td>\n",
       "      <td>\\n\\n\\n       \\n      The weather still sucks. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>[weather, suck, nice, sunny, warm, day, weekend]</td>\n",
       "      <td>0.488362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id              Date  \\\n",
       "57148   3348936       17,May,2004   \n",
       "602779   449628  27,February,2003   \n",
       "592824   320317   06,January,2002   \n",
       "29972   2627097  06,February,2004   \n",
       "31157   2661577      18,July,2004   \n",
       "462227  3932756    04,August,2004   \n",
       "635702    75671    03,August,2004   \n",
       "154433  4147395    11,August,2004   \n",
       "288270  2576645     15,March,2004   \n",
       "504350  1107146  17,February,2003   \n",
       "514795   958176     13,March,2003   \n",
       "228003  1842721  05,February,2004   \n",
       "92294   3593363      29,July,2004   \n",
       "514751   958176  17,February,2003   \n",
       "590083   307112      02,July,2004   \n",
       "572927  1784456     24,March,2002   \n",
       "504394  1107146     13,March,2003   \n",
       "30618   2637211    01,August,2004   \n",
       "104290  3688047      24,June,2004   \n",
       "234168  1915813     25,April,2004   \n",
       "\n",
       "                                                     Post  Gender  Age  \\\n",
       "57148   \\n\\n    \\n       As always the weather has let...    male   25   \n",
       "602779  \\n\\n\\n       \\n        urlLink Weather from We...    male   34   \n",
       "592824  \\n\\n    \\n         Little under the weather to...    male   36   \n",
       "29972   \\n\\n    \\n       \\n      Ah HA! I have real we...  female   47   \n",
       "31157   \\n\\n    \\n       11:00am 1-19-2004  urlLink My...    male   23   \n",
       "462227  \\n\\n     \\n         Great weather we are havin...  female   25   \n",
       "635702  \\n\\n     \\n       urlLink    If i am talking a...    male   36   \n",
       "154433  \\n\\n\\t \\n      I fucking hate The Weather Chan...    male   17   \n",
       "288270  \\n\\n\\t \\n      As you may have noticed, I have...  female   16   \n",
       "504350           \\n\\n    \\n       \\n      Nice.\\n      \\n  female   16   \n",
       "514795  \\n\\n    \\n       \\n      Will, be nice.\\n      \\n    male   17   \n",
       "228003                      \\n\\n\\t \\n      Nice. \\n    \\n    male   24   \n",
       "92294   \\n\\n\\t \\n      I've got nothing nice to say. \\...    male   17   \n",
       "514751           \\n\\n    \\n       \\n      Nice.\\n      \\n    male   17   \n",
       "590083              \\n\\n     \\n      nice \\n     \\n    \\n  female   24   \n",
       "572927  \\n\\n    \\n       \\n      You're so nice to me....  female   16   \n",
       "504394  \\n\\n    \\n       \\n      Will, be nice.\\n      \\n  female   16   \n",
       "30618   \\n\\n    \\n       \\n      Ever wonder what the ...  female   23   \n",
       "104290  \\n\\n\\t \\n      English weather sucks!\\n     \\n...  female   15   \n",
       "234168  \\n\\n\\n       \\n      The weather still sucks. ...    male   27   \n",
       "\n",
       "           Industry    Astrosign  \\\n",
       "57148       Student       Gemini   \n",
       "602779       indUnk        Aries   \n",
       "592824   Technology       Pisces   \n",
       "29972        indUnk       Taurus   \n",
       "31157        indUnk        Libra   \n",
       "462227    Marketing      Scorpio   \n",
       "635702  Engineering        Aries   \n",
       "154433     Military       Taurus   \n",
       "288270      Student       Cancer   \n",
       "504350      Student        Libra   \n",
       "514795   Non-Profit       Gemini   \n",
       "228003       indUnk  Sagittarius   \n",
       "92294       Student       Taurus   \n",
       "514751   Non-Profit       Gemini   \n",
       "590083         Arts        Virgo   \n",
       "572927      Student     Aquarius   \n",
       "504394      Student        Libra   \n",
       "30618       Student    Capricorn   \n",
       "104290       indUnk        Virgo   \n",
       "234168       indUnk  Sagittarius   \n",
       "\n",
       "                                           Post_tokenized  Relevance  \n",
       "57148                                      [weather, let]   0.667551  \n",
       "602779  [urllink, weather, weatherbug, include, weathe...   0.588184  \n",
       "592824                     [little, weather, today, feel]   0.574015  \n",
       "29972                               [real, weather, need]   0.573347  \n",
       "31157                            [urllink, weather, suck]   0.573257  \n",
       "462227                              [great, weather, far]   0.570216  \n",
       "635702                     [urllink, talk, weather, mean]   0.566359  \n",
       "154433  [fucking, hate, weather, channel, seriously, c...   0.561749  \n",
       "288270  [notice, change, template, blog, parade, templ...   0.557421  \n",
       "504350                                             [nice]   0.529760  \n",
       "514795                                             [nice]   0.529760  \n",
       "228003                                             [nice]   0.529760  \n",
       "92294                                              [nice]   0.529760  \n",
       "514751                                             [nice]   0.529760  \n",
       "590083                                             [nice]   0.529760  \n",
       "572927                                             [nice]   0.529760  \n",
       "504394                                             [nice]   0.529760  \n",
       "30618   [wonder, weather, like, house, jerm, weather, ...   0.520364  \n",
       "104290                           [english, weather, suck]   0.490733  \n",
       "234168   [weather, suck, nice, sunny, warm, day, weekend]   0.488362  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Welcome to the Semantic Search Engine!\\n\\nKindly enter the keyword/sentence/query you are looking for:\\t\")\n",
    "word = input()\n",
    "print(\"\\n How many relevant results who you like me to show?:\\t\")\n",
    "r = input()\n",
    "r = int(r)\n",
    "\n",
    "result_df = SemanticSearch(word,r)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Making use of POS and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above cell output from our semantic search is of particular interest to us. We can see that when we expand the relevant results to a higher number (20 in this case) we see that in some cases the word nice seems to get a higher weightage while our sentence subject was \"weather\" . \n",
    "\n",
    "### We could use Part of Speech in this case and give more weightage to \"weather\" than \"nice\". In other cases, we can make sure of Name Entity Recognition and give more weight to those words.\n",
    "\n",
    "### Given a week time to accomplish the task, and to maximize the output:efficiency ratio, I had decided to omit those two parts from my pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utlitizing Date column to sort our search based on recent/older posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another factor on which we can model is sorting by converting the date column to a datetime object and sorting based on recent/ older results. The hurdle which I encountered while trying to do this was that the date column has entries in the month column in different languages( Eg., Romanian, Italian, French.. to name a few)\n",
    "\n",
    "## For more details checkout Scrapdrafts/DetectLanguagesinDates.ipynb for validation of the above statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we could potentially topic model our data based on Gender, Industry, Age (AstroSign could also possibly be included, though that would be a stretch :D) to make note of the jargon that particular group of people use and give it more weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hope you enjoyed going through the code. Any inputs on improving the comments, readability or the code itself are most welcome :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
